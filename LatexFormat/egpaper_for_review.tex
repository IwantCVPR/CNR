\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

% \cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{Convolution Neural Ruler: A Measurement Method and Application in Multi-Oriented Text Detection}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   In this paper, we propose a method called ‘Convolution Neural Ruler’ (CNR) to measure distances by summing values of different dimensions which is just like using a ruler. To demonstrate the efficiency of CNR, we apply it into a non-proposal based detection system which is used to detect multi-oriented scene texts with various sizes, orientations and aspect ratios. The results, especially for long and multi-oriented texts, verify the reasonableness and efficiency of the proposed method. On benchmark ICDAR2015 which focuses on incidental texts, the F1-measure achieves 77\% surpassing the second place by a large extent. We also give convincing results on benchmark ICDAR2013 and MSRA-TD500.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

Recently, convolution neural networks (CNNs) have significantly driven the improvements of object detection. Unlike object classification or segmentation which only perform classification on image-level or pixel-level, object detection requires not only to recognize the object, but also to measure the bound of each object. As a result, most CNN based detection structures like [Fast RCNN] [Faster RCNN] [SSD] [YOLO] [Densebox] are multi-task structure with one recognizer for classification and one regressor for localization.

According to the design of regression task, we can divide recent detection methods into two groups: proposal based regression method [Fast RCNN] [Faster RCNN] [SSD] and non-proposal based regression [YOLO] [Densebox] method. The former predicts the offset from the proposal to the ground truth and the latter directly predicts the bound of an object. Current high performance detection structures like [Faster RCNN] [SSD] are belong to proposal based regression method and they benefit from the easier regression task in which proposals are not far from the corresponded ground truth. On the contrary, the non-proposal based regression method struggles to localize objects correctly which has been pointed out in [YOLO].

Despite proposal based regression is superior to non-proposal based one, it cannot avoid the problem that it will be difficult to get ideal results if we have to output a bounding box whose aspect ratio is too large and this will be normally encountered in detecting text lines [See Fig.1]. Simply increasing the diversity of ‘anchors’ like [Deep-Text] may be effective but sacrifices efficiency of the whole detection system.

The reason why non-proposal based regression struggles to localize object correctly, as well as the non-proposal based regression fail to localize object with too large aspect ratio, is that it is difficult to directly regress a distribution with large variance by using the Euclidean Loss. And it is also the case even for the toy problem shown in Fig.2.

To solve this problem, we propose the ‘Convolution Neural Ruler’ (CNR) to measure the distance like a ruler. First we set several dimensions $D_i (i\in \{1, 2 ..., N\})$ like kilometer, meter and millimeter. Then we regress values $V_i (i\in \{1, 2 ..., N\})$ ranging from zero to one for each dimension. Finally we combine the values of each dimension by $\sum_{i=1}^{N} D_{i} \cdot V_{i}$ as the predicted result. The whole process is just like how we use a rule --- we actually take the measurements by adding values multiple dimensions.

To test the efficiency of CNR, we design a non-proposal based detection system and choose scene texts whose aspect ratios and orientations vary much more than general objects as the detection targets. The results, especially for long and multi-oriented texts, given by our method demonstrate the reasonableness and efficiency of the proposed method.

To sum up, the main contributions of this paper are in three folds: firstly, we propose a method called ‘Convolution Neural Ruler’ to make it possible directly regress arbitrary values; secondly, we propose a non-proposal based detection system to localize multi-oriented scene text with CNR embedded to accurately determine the bounds of text. Benefiting from the precise bound given by our system, we have got state of the art result on benchmarks with multi-oriented text surpassing recent results with a large margin. 

The reminding parts of this paper are arranged as follows: Section 2 gives a brief review of bounding box regression and multi-oriented text detection, Section 3 introduces the details of our detection system including , Section 4 displays the results and analysis of reasonableness of CNR and Section 5 offers a conclusion of our work.

\section{Related Work}
\subsection{Bounding box regression}
Most detection structures based on convolution neural network are multi-task structure with a classifier for object recognition and a regressor for bounding box regression. 
[overfeat] trains the regressor by minimizing the $\ell_2$ loss between predicted and true bounding boxes. 
[YOLO] trains the regressor much like [overfeat] and for better performance it predicted the square root value of box size. However, both [overfeat] and [YOLO] gave less satisfying results on localization. 
Methods like [rcnn] [sppnet] [fast-rcnn] [multibox] handle the regressor training by an indirect way where they predict the relative distances between proposals and corresponded ground truths. Since relative distances are much smaller, the localization results come to be more accurate.
While for [faster-rcnn] [ssd], both of them convert region proposals into 'anchors' and lay more emphasis on end-to-end structure and less time consuming.
However, if we have to detect objects with variety of sizes, orientation and aspect ratios by an end-to-end way, resorting to a non-proposal based detection method rather than more complicated 'anchors' [deep text] and iterative localization [fast-rcnn] [detection-via-multiregionANDsegmentation] would be more effective and efficient.

\subsection{Multi-oriented text detection}
Most research on multi-oriented text detection follows a 'character to line' strategy which localizes characters beforehand and then groups characters into text lines by rules. Previous works on character detection are mainly based on classifying connected components [] []. Recently [FCN-text] has proposed a method which takes advantages of fully convolution network [FCN] to segment the text line and character regions instead of recognizing connected components. [CTPN-eccv16] regards the vertical slices of a text line as characters and connected them by a Bi-directional LSTM. No matter how the referred methods deal with characters or text line, they cannot skip the character localization stage. Although [deep-text] can directly outputs words' bounding boxes without detecting letters, it is suitable to deal with horizontal text and detecting excessive long and multi-oriented text based on this method may require more complicated design of 'anchors' [faster rcnn].



\section{Non-proposal Based Network}
The non-proposal structure proposed by us is illustrated in Fig.2.

In this section, we describe the proposed method in detail. First we give an overview of the non-proposal based detection system, Second we formulated 'CNR' embedded in our detection system. Third we 

\subsection{Network structure}
The network structure is shown in Fig.3. Since the regressor is require to measure length up to the input image size, the receptive field of network is designed to be larger than the input image size. And for precise measurement of small object, we should also fuse low-level features to provide detailed information. 
\subsection{Convolution neural ruler}

\subsection{NMS}

\section{Experiments}
\subsection{Experiments on toy dataset}

\subsection{Experiments on text detection}
\subsection{Dimension analysis of CNR} % may be unreasonable = = then we drop this subsection
To explain the reasonableness of CNR, we output the value for each dimension and check whether our model learn to measure like a ruler.

\section{Conclusion}

\section{title}

%-------------------------------------------------------------------------

%-------------------------------------------------------------------------


\subsection{Mathematics}

Please number all of your sections and displayed equations.  It is
important for readers to be able to refer to any particular equation.  Just
because you didn't refer to it in the text doesn't mean some future reader
might not need to refer to it.  It is cumbersome to have to use
circumlocutions like ``the equation second from the top of page 3 column
1''.  (Note that the ruler will not be present in the final copy, so is not
an alternative to equation numbers).  All authors will benefit from reading
Mermin's description of how to write mathematics:
\url{http://www.pamitc.org/documents/mermin.pdf}.


\subsection{Blind review}
\begin{figure}[t]
\begin{center}
\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   %\includegraphics[width=0.8\linewidth]{egfigure.eps}
\end{center}
   \caption{Example of caption.  It is set in Roman so that mathematics
   (always set in Roman: $B \sin A = A \sin B$) may be included without an
   ugly clash.}
\label{fig:long}
\label{fig:onecol}
\end{figure}


so prefer \cite{Alpher03,Alpher02,Authors14} to
\cite{Alpher02,Alpher03,Authors14}.


\begin{figure*}
\begin{center}
\fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
\end{center}
   \caption{Example of a short caption, which should be centered.}
\label{fig:short}
\end{figure*}


%-------------------------------------------------------------------------
\subsection{Footnotes}

Please use footnotes\footnote {This is what a footnote looks like.  It
often distracts the reader from the main flow of the argument.} sparingly.
Indeed, try to avoid footnotes altogether and include necessary peripheral
observations in
the text (within parentheses, if you prefer, as in this sentence).  If you
wish to use a footnote, place it at the bottom of the column on the page on
which it is referenced. Use Times 8-point type, single-spaced.






{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
